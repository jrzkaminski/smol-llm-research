{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFOrBw4o7qtQ",
        "outputId": "c2a9798e-476b-4e5d-a928-8232d91490b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.3.0)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7JbfHcO7sRm",
        "outputId": "2c9499b2-6b93-41b0-ead3-0e33568805f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import jsonlines\n",
        "import os\n",
        "import time\n",
        "\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "u3quqNSd7dVc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GENAI:\n",
        "    def __init__(self, model) -> None:\n",
        "        self.model = model\n",
        "        env_path = \"../.env\"\n",
        "        load_dotenv(env_path)\n",
        "        self.API_KEY = \"sk-or-vv-7fcc4ab944ca013feb7608fb7c0f001e5c12c32abf66233aad414183b4191a79\"\n",
        "        self.URL = \"https://api.vsegpt.ru/v1/chat/completions\"\n",
        "\n",
        "    def ask_batch(self, prompt, temperature=0.7, max_new_tokens=1000, greedy=True):\n",
        "        headers = {\n",
        "            'Content-Type': 'application/json',\n",
        "            'Authorization': f'Bearer {self.API_KEY}'\n",
        "        }\n",
        "        decoding_method = 'greedy' if greedy else 'sample'\n",
        "\n",
        "        messages = [{\"role\": \"user\", \"content\": message} for message in prompt]\n",
        "        data = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": temperature,\n",
        "            \"max_tokens\": max_new_tokens,\n",
        "            # \"n\": len(messages)\n",
        "        }\n",
        "        # print('---------------------------------')\n",
        "        # print(data)\n",
        "        response = requests.post(self.URL, headers=headers, json=data)\n",
        "        # print(response)\n",
        "        # print(response.content)\n",
        "        # print(json.loads(response.content.decode('utf-8')))\n",
        "        # print(json.loads(response.content.decode('utf-8'))['choices'][0]['message']['content'])\n",
        "        # print('---------------------------------')\n",
        "        # return\n",
        "        try:\n",
        "            result = json.loads(response.content.decode('utf-8'))['choices'][0]['message']['content']\n",
        "            return result\n",
        "        except:\n",
        "            return None\n",
        "        # output_list = [x['generated_text'] for x in response.json()['results']]\n",
        "        # return output_list\n",
        ""
      ],
      "metadata": {
        "id": "fj3Rr-sC77w-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llm_paraphrase(api_str_list, save_path, model):\n",
        "    def chunk_list(lst, chunk_size):\n",
        "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "    single_api_str_list = [api.split('[SEP]') for api in api_str_list]\n",
        "    single_api_str_list = [item.strip() for sublist in single_api_str_list for item in sublist]  # flatten\n",
        "    genai_obj = GENAI(model=model)  # model can be any generative model\n",
        "    api_to_str = {}\n",
        "    chunked_list = chunk_list(single_api_str_list[:400], 5)  # chucked api lists with batch size 5\n",
        "    # print(f\"LEN: {len(single_api_str_list)}\")\n",
        "    # return\n",
        "    for idx, batch in enumerate(chunked_list):\n",
        "        print(f'Processing batch {idx} out of {len(chunked_list)}')\n",
        "        prompts = []\n",
        "        outputs = []\n",
        "        print(\"-----\")\n",
        "        for api in batch:\n",
        "            output_string = f'intent: {api}'\n",
        "            prompt = f'Convert the following intent and its parameteres into an imperative sentence. Do not copy the API or its parameters as is in the output sentence.\\n\\nInput:\\n' + output_string + '\\nOutput:\\n'\n",
        "            # prompts.append(prompt)\n",
        "            outputs.append(genai_obj.ask_batch([prompt]))\n",
        "        # try:\n",
        "        #     outputs = genai_obj.ask_batch(prompts)\n",
        "        #     print(outputs)\n",
        "        # except Exception as err:\n",
        "        #     print('Connection error at ask_batch')\n",
        "        #     break\n",
        "            # time.sleep(5)\n",
        "            # outputs = genai_obj.ask_batch(prompts)\n",
        "        for txt, api in zip(outputs, batch):\n",
        "            api_to_str[api] = txt\n",
        "        # uncomment to save llm phrases with interval of 100 batches\n",
        "        # if len(api_to_str) > 0 and len(api_to_str) % 100 == 0:\n",
        "        #     with open(save_path, 'w+') as file:\n",
        "        #         json.dump(api_to_str, file, indent=4)\n",
        "    # uncomment to save all llm phrases\n",
        "    # with open(save_path, 'w+') as file:\n",
        "    #     json.dump(api_to_str, file, indent=4)\n",
        "    return api_to_str"
      ],
      "metadata": {
        "id": "6uJdVC888SGu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_raw_data(raw_data_dir):\n",
        "    # data_files = [item for item in os.listdir(raw_data_dir) if\n",
        "    #               os.path.isfile(os.path.join(raw_data_dir, item)) and not item == 'schema.json']\n",
        "    data_files = ['dialogues_001.json']\n",
        "    processed_data = []\n",
        "    for file in tqdm(data_files):\n",
        "        print(file)\n",
        "        data = json.load(open(os.path.join(raw_data_dir, file)))\n",
        "        print(len(data))\n",
        "        for d in tqdm(data):  # each dialog\n",
        "            for t in d['turns']:  # each turns\n",
        "                if t['speaker'] == 'USER':\n",
        "                    turn_intent_slots = []\n",
        "                    for f in t['frames']:\n",
        "                        if f['state']['slot_values'] and not f['state']['active_intent'] == 'NONE':\n",
        "                            turn_slots = []\n",
        "                            for slot, values in f['state']['slot_values'].items():\n",
        "                                turn_slots.append(f'{slot} = {values[0]}')\n",
        "                            slot_str = ' ; '.join(turn_slots)\n",
        "                            turn_intent_slots.append(f\"{f['state']['active_intent']}({slot_str})\")\n",
        "                    api_str = ' [SEP] '.join(turn_intent_slots)\n",
        "                    processed_data.append({\n",
        "                        'dialog_id': d['dialogue_id'],\n",
        "                        'speaker': 'USER',\n",
        "                        'input': t['utterance'],\n",
        "                        'output': api_str\n",
        "                    })\n",
        "                else:\n",
        "                    processed_data.append({\n",
        "                        'dialog_id': d['dialogue_id'],\n",
        "                        'speaker': 'BOT',\n",
        "                        'input': t['utterance'],\n",
        "                        'output': ''\n",
        "                    })\n",
        "    return processed_data"
      ],
      "metadata": {
        "id": "4q3MLHY58W-m"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GSxTCOCO7WZW"
      },
      "outputs": [],
      "source": [
        "def curate_llm_based_data(data_dir_root, save_dir, dataset_name, model):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    # splits = ['train', 'test', 'dev']\n",
        "    splits = ['dev']\n",
        "    for split in splits:\n",
        "        print(f'======= {split} =======')\n",
        "        data_dir = os.path.join(data_dir_root, split)\n",
        "        raw_data = extract_raw_data(data_dir)  # combine multiple dialog files\n",
        "\n",
        "        # uncomment to save intermediate data (raw data)\n",
        "        # raw_save_path = os.path.join(save_dir, f'{dataset_name}-raw-{split}.jsonl')\n",
        "        # with jsonlines.open(raw_save_path, \"w\") as writer:\n",
        "        #     writer.write_all(raw_data)\n",
        "\n",
        "        api_str_list, api_str_dialog_map = [], {}\n",
        "        for d in raw_data:\n",
        "            if d['output'] and 'NONE(' not in d['output']:\n",
        "                api_str_list.append(d['output'])\n",
        "                api_str_dialog_map.setdefault(d['dialog_id'], []).append(d['output'])\n",
        "        # print()\n",
        "        # print(\"---------------------\")\n",
        "        # print(api_str_list)\n",
        "        # print(api_str_dialog_map)\n",
        "        # print(\"---------------------\")\n",
        "\n",
        "        llm_paraphrase_save_path = os.path.join(save_dir, f'{dataset_name}-llm-{split}.jsonl')\n",
        "        api_to_str = generate_llm_paraphrase(api_str_list, llm_paraphrase_save_path, model)\n",
        "\n",
        "        # reconstruct the data with llm-paraphrases\n",
        "        processed_data_dict_list = []\n",
        "        for _, conv in api_str_dialog_map.items():\n",
        "            input_list, output_list, api_list, intents = [], [], [], []\n",
        "            for apis in conv:\n",
        "                api_list.extend(apis.split('[SEP]'))\n",
        "            for api in api_list:\n",
        "                intent = api[:api.index('(')]\n",
        "                if intent not in intents:\n",
        "                    intents.append(intent)\n",
        "            api_list = [max([api for api in api_list if api.startswith(intent)], key=len) for intent in\n",
        "                        intents]  # take the longest string of intents (more slots).\n",
        "            for api in api_list:\n",
        "                if api in api_to_str.keys():\n",
        "                    output_list.append(api)\n",
        "                    api_str = api_to_str[api].lower()\n",
        "                    api_str = api_str + '.' if not api_str.endswith('.') else api_str\n",
        "                    input_list.append(api_str)\n",
        "            if input_list and output_list:\n",
        "                processed_data_dict_list.append(\n",
        "                    {\n",
        "                        'input': ' '.join(input_list),\n",
        "                        'output': ' [SEP] '.join(output_list)\n",
        "                    }\n",
        "                )\n",
        "\n",
        "        # save processed outputs\n",
        "        processed_data_save_path = os.path.join(save_dir, f'{dataset_name}-processed-{split}.jsonl')\n",
        "        with jsonlines.open(processed_data_save_path, \"w\") as writer:\n",
        "            writer.write_all(processed_data_dict_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    \"data_dir\": \"drive/MyDrive/bench_data/MultiWOZ\",\n",
        "    \"save_dir\": \"drive/MyDrive/processed_bench_data/MultiWOZ\",\n",
        "    \"dataset_name\": \"multiWOZ\",\n",
        "    \"model\": \"meta-llama/llama-3.1-70b-instruct\"\n",
        "}\n",
        "\n",
        "# generation\n",
        "# curate_llm_based_data(args[\"data_dir\"], args[\"save_dir\"], args[\"dataset_name\"], args[\"model\"])"
      ],
      "metadata": {
        "id": "cVqApF3M8a6s"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yShONAZ8PYM1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11BBPCUkPYJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9k2njwUDPYHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "44WziBwDPYEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7yWArxSPYCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PAksnBSAB70Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}